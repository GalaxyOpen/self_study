{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  표제어 추출 (Lemmatization) , 어간 추출 (Stemming)"
      ],
      "metadata": {
        "id": "QCVdOF5kcm8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- 표제어 추출 (Lemmatization)\n",
        "  - 우선 Lemma라고 부르는 단어는 우리나라 말로 번역할 때 '표제어'라는 단어로 번역이 되고, 의미로는 '기본 사전형 단어' 정도의 의미를 갖는다.\n",
        "  - 표제어 추출을 하는 이유는 단어들이 다른 형태를 가지더라도 그 뿌리 단어를 찾아가서 단어의 개수를 줄일 수 있는지 판단하는데 쓴다.\n",
        "  - ex : am, are is 의 표제어는 be 라고 볼 수 있다.\n",
        "\n",
        "- 어간(stem) : 단어의 의미를 담고 있는 단어의 핵심 부분.\n",
        "- 접사(affix) : 단어에 추가적인 의미를 주는 부분.\n",
        "\n",
        "NLTK 에서는 표제어 추출을 위한 도구인 WordNetLemmatizer를 지원하고, 이를 통해 실습해볼 수 있다."
      ],
      "metadata": {
        "id": "dA1zb_1PV8OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install NLTK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2ZWpjmtWEqO",
        "outputId": "4e028171-66ef-4639-8b7f-0c2f5771ee39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from NLTK) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from NLTK) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from NLTK) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from NLTK) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hMZtnl7doUk",
        "outputId": "4b607607-c6c1-4569-8840-3a6413e62589"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "\n",
        "print('표제어 추출 전 : ', words)\n",
        "print('표제어 추출 후 : ', [lemmatizer.lemmatize(word) for word in words])\n",
        "\n",
        "# 표제어 추출 전 :  ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "# 표제어 추출 후 :  ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n",
        "# 표제어 추출의 경우 단어 형태가 적절히 보존되긴 함.\n",
        "# 하지만 dy나 ha 처럼 오류가 나기도 하는데, 표제어 추출기(lemmatizer)가 본래 품사 정보를 알아야만 정확한 결과를 얻을 수 있기 때문임."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPiL09jNcrlc",
        "outputId": "536cf264-a01e-42c6-c416-2a4b6f61c012"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "표제어 추출 전 :  ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "표제어 추출 후 :  ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WordNetLemmatizer는 입력으로 단어가 동사 품사를 알려줄 수 있음.\n",
        "# 예시\n",
        "\n",
        "lemmatizer.lemmatize('dies', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_r4rGNoldcfv",
        "outputId": "6004f3d7-87fb-463d-a7a5-246e92384946"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'die'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('watched', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FNtUtxNLe45o",
        "outputId": "e56e6a3a-360b-42ee-df6a-5d236b9cdb3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'watch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('has', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cg4i2x7be8SF",
        "outputId": "e9224374-b664-4d4d-ea90-6dff1ff3a074"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 어간 추출(Stemming)\n",
        "어간(Stem)을 추출하는 작업을 어간 추출(stemming)이라고 함. 형태학적 분석을 단순화한 버전이라 볼 수도 있고, 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업이라고 볼 수도 있음."
      ],
      "metadata": {
        "id": "aRrr5HNYe9Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "senentece = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
        "tokenized_sentence = word_tokenize(senentece)\n",
        "\n",
        "print('어간 추출 전 : ', tokenized_sentence)\n",
        "print('어간 추출 후 : ', [stemmer.stem(word) for word in tokenized_sentence])\n",
        "\n",
        "# Porter 알고리즘의 상세 규칙은 마틴 포터의 홈페이지에서 확인할 수 있지만, 규칙 기반의 접근을 하고 있기 때문에 사전에 없는 단어가 다수 포함되어 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNWJHMymjJin",
        "outputId": "7ae8a451-7a55-418f-dfe6-1f0d4d9d8d65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 :  ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
            "어간 추출 후 :  ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 일부 규칙 예시\n",
        "words = ['formalize', 'allowance', 'electricical']\n",
        "\n",
        "print('어간 추출 전 : ', words)\n",
        "print('어간 추출 후 : ', [stemmer.stem(word) for word in words])\n",
        "\n",
        "# alize => al , ance => 제거함, ical => ic 로 변환됨을 알 수 있음."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bxDFl0-jZSl",
        "outputId": "e74c2b4d-f792-48a3-8e67-76eded88062c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 :  ['formalize', 'allowance', 'electricical']\n",
            "어간 추출 후 :  ['formal', 'allow', 'electric']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "\n",
        "print('어간 추출 전 : ', words)\n",
        "print('포터스테머의 어간 추출 후 : ', [porter_stemmer.stem(word) for word in words])\n",
        "print('랭커스터 스테머의 어간 추출 후 : ', [lancaster_stemmer.stem(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nsrw8rulX2_",
        "outputId": "f9037469-5367-4a9d-8b96-6b38e323d2f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 :  ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "포터스테머의 어간 추출 후 :  ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
            "랭커스터 스테머의 어간 추출 후 :  ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syFKNsEkovgA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}